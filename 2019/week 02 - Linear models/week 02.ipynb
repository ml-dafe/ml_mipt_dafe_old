{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар 2 – Линейные модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(palette='deep', style='darkgrid', rc={\"figure.figsize\": (15, 4)})\n",
    "import scipy.stats as st\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируем исскуственные данные, на основе функции:\n",
    "$$f(x) = 4x+5$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_function(x):\n",
    "    return 4*x+5\n",
    "\n",
    "x_true = np.array([-2,2])\n",
    "y_true = lin_function(x_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_true, y_true, linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "x = np.random.rand(n,1)*4-2\n",
    "e = np.random.rand(n,1)*4-2\n",
    "y = lin_function(x) + e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y, color='g')\n",
    "plt.plot(x_true, y_true, linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Аналитический метод\n",
    "$$\\hat \\theta = \\bigl(X^T \\cdot X  \\bigr)^{-1} \\cdot X^T \\cdot y $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_matrix = np.c_[np.ones((n,1)),x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "thetha_matrix = np.linalg.inv(x_matrix.T.dot(x_matrix)).dot(x_matrix.T).dot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetha_matrix.T[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Свободный член: {[0][0]:.7}\".format(thetha_matrix.T))\n",
    "print(\"Коэфициент: {[0][1]:.7}\".format(thetha_matrix.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lr = LinearRegression()\n",
    "lr.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Свободный член: {:.7}\".format(lr.intercept_[0]))\n",
    "print(\"Коэфициент: {:.7}\".format(lr.coef_[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y, color='g')\n",
    "plt.scatter(x, lr.predict(x), color='r')\n",
    "plt.plot(x_true, y_true, linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пакетный градиентный спуск\n",
    "\n",
    "$$\\nabla MSE(\\theta)= \\frac{2}{l} X^T \\cdot \\bigl(X \\cdot \\theta - y \\bigr) $$\n",
    "\n",
    "### Реализация в numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "eta = 0.1  # learning rate\n",
    "n_iterations = 100\n",
    "\n",
    "\n",
    "theta = np.random.randn(2,1)  # random initialization\n",
    "\n",
    "plt.scatter(x, y, color='g')\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    if iteration < 10:\n",
    "        plt.plot(x_true, x_true*theta[1]+theta[0], linewidth=1, color='r')\n",
    "    gradients = 2/n * x_matrix.T.dot(x_matrix.dot(theta) - y)\n",
    "    theta = theta - eta * gradients\n",
    "\n",
    "plt.plot(x_true, y_true, linewidth=1)\n",
    "plt.show()\n",
    "\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Слишком маленький шаг обучения (learning rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.01  # learning rate\n",
    "n_iterations = 100\n",
    "\n",
    "\n",
    "theta = np.random.randn(2,1)  # random initialization\n",
    "\n",
    "plt.scatter(x, y, color='g')\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    if iteration < 10:\n",
    "        plt.plot(x_true, x_true*theta[1]+theta[0], linewidth=1, color='r')\n",
    "    gradients = 2/n * x_matrix.T.dot(x_matrix.dot(theta) - y)\n",
    "    theta = theta - eta * gradients\n",
    "\n",
    "plt.plot(x_true, y_true, linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Слишком большой шаг обучения (learning rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 1.01  # learning rate\n",
    "n_iterations = 100\n",
    "\n",
    "\n",
    "theta = np.random.randn(2,1)  # random initialization\n",
    "\n",
    "plt.scatter(x, y, color='g')\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    if iteration < 10:\n",
    "        plt.plot(x_true, x_true*theta[1]+theta[0], linewidth=1, color='r')\n",
    "    gradients = 2/n * x_matrix.T.dot(x_matrix.dot(theta) - y)\n",
    "    theta = theta - eta * gradients\n",
    "\n",
    "plt.plot(x_true, y_true, linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Уменьшение шага на каждой итерации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 1  # learning rate\n",
    "n_iterations = 1000\n",
    "\n",
    "theta = np.random.randn(2,1)  # random initialization\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    gradients = 2/n * x_matrix.T.dot(x_matrix.dot(theta) - y)\n",
    "    theta = theta - (eta/(iteration+1)) * gradients\n",
    "\n",
    "\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate - гипперпараметр, и можно воспользоваться GridSearchCV, однако чтобы не учить каждый раз такое кол-во итераций, мы можем измерять норму градиента, и прекращать спуск, когда он \"затух\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.1  # learning rate\n",
    "n_iterations = 1000\n",
    "tol = 0.00001\n",
    "\n",
    "theta = np.random.randn(2,1)  # random initialization\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    gradients = 2/n * x_matrix.T.dot(x_matrix.dot(theta) - y)\n",
    "    if np.linalg.norm(gradients) < tol:\n",
    "        break\n",
    "    theta = theta - eta * gradients\n",
    "\n",
    "print('Градиент затух на {} итерации '.format(iteration))\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Реализация в Scikit-Learn отсутствует__\n",
    "  \n",
    "  \n",
    "# Cтохастический градиентный спуск  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "\n",
    "def learning_schedule(t):\n",
    "    return t0 / (t + t1)\n",
    "\n",
    "t0, t1 = 5, 100  # learning schedule hyperparameters\n",
    "\n",
    "\n",
    "theta = np.random.randn(2,1)  # random initialization\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(n):\n",
    "        random_index = np.random.randint(n)\n",
    "        xi = x_matrix[random_index:random_index+1]\n",
    "        yi = y[random_index:random_index+1]\n",
    "        gradients = 2 * xi.T.dot(xi.dot(theta) - yi)\n",
    "        eta = learning_schedule(epoch * n + i)\n",
    "        theta = theta - eta * gradients\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDRegressor(tol=0.0001)\n",
    "#The stopping criterion. If it is not None, the iterations will stop when (loss > previous_loss - tol).\n",
    "sgd.fit(x,y)\n",
    "sgd.intercept_, sgd.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Влияние выбора функции потерь\n",
    "По мотивам [Семинара курса ML на ФИВТ](https://github.com/ml-mipt/ml-mipt/blob/master/week02_linear_reg/week02_linear_regression.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/data_preprocessed.json') as file:\n",
    "    X = pd.read_json(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_subset = X[[7, 15]].values\n",
    "# add two outliers\n",
    "X_subset_modified = np.vstack((X_subset, [[1, 90], [2, 50]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_points_and_plot_line_MSE(X_subset):\n",
    "    plt.scatter(X_subset[:, 0], X_subset[:, 1])\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_subset[:, 0][:, None], X_subset[:, 1])\n",
    "    grid = np.linspace(0, 2, 100)\n",
    "    line = lr.predict(grid[:, None])\n",
    "    plt.plot(grid, line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "scatter_points_and_plot_line_MSE(X_subset)\n",
    "plt.title('Без шумовых признаков')\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.subplot(1, 2, 2)\n",
    "scatter_points_and_plot_line_MSE(X_subset_modified)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel(\"x\")\n",
    "plt.title('С шумовыми признаками')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из-за шумовых объектов прямая достаточно сильно изменила наклон. Поэтому вместо MSE часто используют Mean Absoulte Error: $$L(y_i, a(x_i)) = |y_i - a(x_i)|$$\n",
    "Теперь обучим регрессию, оптимизируя MAE. В sklearn такая регрессия не реализована, но можно использовать модуль statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_points_and_plot_line_MAE(X_subset):\n",
    "    mod = smf.quantreg('f15 ~ f7', pd.DataFrame(data=X_subset, columns=[\"f7\", \"f15\"])) # задаеем зависимость и передаем данные\n",
    "    res = mod.fit(q=0.5)\n",
    "    plt.scatter(X_subset[:, 0], X_subset[:, 1])   # визуализируем точки\n",
    "    grid = np.linspace(0, 2, 100)\n",
    "    plt.plot(grid, grid * res.params[\"f7\"] + res.params[\"Intercept\"])   # визуализируем прямую\n",
    "    return mod, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Без шумовых признаков')\n",
    "model, result = scatter_points_and_plot_line_MAE(X_subset)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('С шумовыми признаками')\n",
    "model, result = scatter_points_and_plot_line_MAE(X_subset_modified)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel(\"x\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прямая не изменила направление из-за выбросов.\n",
    "Попробуем добавить больше шумовых объектов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_subset_modified_twice = np.vstack((\n",
    "    X_subset_modified, \n",
    "    np.random.randint(5, size=60).reshape(-1, 2) * [1, 30],\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "model, result = scatter_points_and_plot_line_MAE(X_subset)\n",
    "plt.title('Без шумовых признаков')\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.subplot(1, 2, 2)\n",
    "model, result = scatter_points_and_plot_line_MAE(X_subset_modified_twice)\n",
    "plt.title('С шумовыми признаками')\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel(\"x\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для примера решения задачи прогнозирования, я взял набор данных Energy efficiency из крупнейшего репозитория UCI.   \n",
    "\n",
    "В нем $X_1 ... X_8$ — характеристики помещения на основании которых будет проводиться анализ, а $y_1,y_2$ — значения нагрузки, которые надо спрогнозировать.\n",
    "- $X_1$\tОтносительная компактность\n",
    "- $X_2$\tПлощадь\n",
    "- $X_3$\tПлощадь стен\n",
    "- $X_4$\tПлощадь потолка\t\n",
    "- $X_5$\tОбщая высота\t\n",
    "- $X_6$\tОриентация\n",
    "- $X_7$\tПлощадь остекления\t\n",
    "- $X_8$\tРаспределенная площадь остекления\t\n",
    "- $y_1$\tНагрузка при обогреве\n",
    "- $y_2$\tНагрузка при охлаждении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/energy_efficiency.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим Матрицу корреляции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увеличим читаемость:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "corr = data.drop(['Y1','Y2'], axis=1).corr()\n",
    "sns.heatmap(corr, square=True, ax=ax, cmap=sns.diverging_palette(220, 10, as_cmap=True))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['Y1','Y2'], axis=1)\n",
    "y = data['Y1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_linear_regression(X_train, Y_train):\n",
    "    return np.linalg.inv(X_train.T.dot(X_train)).dot(X_train.T).dot(y_train)\n",
    "\n",
    "def predict(X, w):\n",
    "    return np.dot(X, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = my_linear_regression(X_train, y_train)\n",
    "print(w)\n",
    "y_train_pred = predict(X_train, w)\n",
    "print('='*10, 'Train', '='*10)\n",
    "print(\"MSE: \", mean_squared_error(y_train, y_train_pred))\n",
    "print(\"R2: \", r2_score(y_train, y_train_pred))\n",
    "y_test_pred = predict(X_test, w)\n",
    "print('='*10, 'Test', '='*10)\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_test_pred))\n",
    "print(\"R2: \", r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим скоррелированные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_droped = data.drop(['X1','X4', 'Y1','Y2'], axis=1)\n",
    "y = data['Y1']\n",
    "X_train_new, X_test_new, y_train, y_test = train_test_split(X_droped, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = my_linear_regression(X_train_new, y_train)\n",
    "print(w)\n",
    "y_train_pred = predict(X_train_new, w)\n",
    "print('='*10, 'Train', '='*10)\n",
    "print(\"MSE: \", mean_squared_error(y_train, y_train_pred))\n",
    "print(\"R2: \", r2_score(y_train, y_train_pred))\n",
    "y_test_pred = predict(X_test_new, w)\n",
    "print('='*10, 'Test', '='*10)\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_test_pred))\n",
    "print(\"R2: \", r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим регуляризацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_linear_regression(X_train, Y_train, l2=0):\n",
    "    return np.linalg.inv(X_train.T.dot(X_train) + l2*np.eye(X_train.shape[1])).dot(X_train.T).dot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = my_linear_regression(X_train, y_train, 1)\n",
    "print(w)\n",
    "y_train_pred = predict(X_train, w)\n",
    "print('='*10, 'Train', '='*10)\n",
    "print(\"MSE: \", mean_squared_error(y_train, y_train_pred))\n",
    "print(\"R2: \", r2_score(y_train, y_train_pred))\n",
    "y_test_pred = predict(X_test, w)\n",
    "print('='*10, 'Test', '='*10)\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_test_pred))\n",
    "print(\"R2: \", r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Посмотрим, как внутри sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "print(linear_model.coef_)\n",
    "y_train_pred = linear_model.predict(X_train)\n",
    "y_test_pred = linear_model.predict(X_test)\n",
    "\n",
    "print('='*10, 'Train', '='*10)\n",
    "print(\"MSE: \", mean_squared_error(y_train, y_train_pred))\n",
    "print(\"R2: \", r2_score(y_train, y_train_pred))\n",
    "y_test_pred = predict(X_test, w)\n",
    "print('='*10, 'Test', '='*10)\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_test_pred))\n",
    "print(\"R2: \", r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = Ridge()\n",
    "linear_model.fit(X_train, y_train)\n",
    "print(linear_model.coef_)\n",
    "y_train_pred = linear_model.predict(X_train)\n",
    "y_test_pred = linear_model.predict(X_test)\n",
    "\n",
    "print('='*10, 'Train', '='*10)\n",
    "print(\"MSE: \", mean_squared_error(y_train, y_train_pred))\n",
    "print(\"R2: \", r2_score(y_train, y_train_pred))\n",
    "y_test_pred = predict(X_test, w)\n",
    "print('='*10, 'Test', '='*10)\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_test_pred))\n",
    "print(\"R2: \", r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = Lasso()\n",
    "linear_model.fit(X_train, y_train)\n",
    "print(linear_model.coef_)\n",
    "y_train_pred = linear_model.predict(X_train)\n",
    "y_test_pred = linear_model.predict(X_test)\n",
    "\n",
    "print('='*10, 'Train', '='*10)\n",
    "print(\"MSE: \", mean_squared_error(y_train, y_train_pred))\n",
    "print(\"R2: \", r2_score(y_train, y_train_pred))\n",
    "y_test_pred = predict(X_test, w)\n",
    "print('='*10, 'Test', '='*10)\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_test_pred))\n",
    "print(\"R2: \", r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
